<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <title>ðŸŽ¹</title>
    <script src="js/visualization.js"></script>
    <style>
      body {
        background-color: #000;
        color: #fff;
        font-family: "Arial", Times, serif;
      }
      .piano-key {
        stroke: #444;
        fill: #000;
      }
    </style>
  </head>
  <body>
    <div>
      <label>
        Source:
        <select id="source">
          <option value="*">ðŸŽ™ Microphone</option>
          <option value="audio/mazurka.webm" selected="selected">Chopin Mazurka in F minor, op. 68 no. 4 (by Pianotomy)</option>
          <option value="audio/chromatic.mp3">Chromatic scale on a piano, ascending</option>
          <option value="audio/sin.wav">Sine wave, 440 Hz</option>
          <option value="audio/saw.wav">Sawtooth wave, 440 Hz</option>
          <option value="audio/squ.wav">Square wave, 440 Hz</option>
          <option value="audio/noise.wav">Pink noise</option>
        </select>
      </label>
      Palette rotation:
      <input id="rotation" type="range" min="0" max="11" step="1" value="0"/>
      Smoothing:
      <input id="smoothing" type="range" min="0" max="0.25" step="any" value="0.05"/>
      (<span id="smoothing-value">0.050</span>s)
    </div>
    <div>
      <audio id="input" src="audio/mazurka.webm" controls></audio>
    </div>
    <div style="text-align: center">
      <canvas id="spectrogram"></canvas>
      <br>
      <svg id="keyboard"></svg>
    </div>
    <script>
      /* global PianoKeyboard, Spectrogram, Palette */
      let audioContext, audioSource, microphoneSource, sdft
      let levels, lastTimestamp, palette

      fetch('palette.json')
        .then(response => response.json())
        .then(data => { palette = new Palette(data) })

      const audioElement = document.getElementById('input')

      const pianoKeyboard = new PianoKeyboard(document.getElementById('keyboard'))
      pianoKeyboard.drawKeyboard()
      const spectrogram = new Spectrogram(
        document.getElementById('spectrogram'),
        pianoKeyboard.keySlices
      )

      function draw (currentTimestamp) {
        if (
          levels !== undefined &&
          palette !== undefined &&
          currentTimestamp !== lastTimestamp
        ) {
          const keyColors = palette.getKeyColors(levels)
          pianoKeyboard.update(keyColors)
          spectrogram.update(keyColors)
          lastTimestamp = currentTimestamp
        }
      }

      async function setupAudio () {
        if (audioContext === undefined) {
          audioContext = new (window.AudioContext || window.webkitAudioContext)()

          // Thanks for nothing, Firefox!
          // https://bugzilla.mozilla.org/show_bug.cgi?id=1572644
          // https://bugzilla.mozilla.org/show_bug.cgi?id=1636121
          // https://github.com/WebAudio/web-audio-api-v2/issues/109#issuecomment-756634198
          const fetchText = url => fetch(url).then(response => response.text())
          const modules = await Promise.all([
            fetchText('js/sdft.js'),
            fetchText('js/pianolizer.js')
          ])
          const blob = new Blob(modules, { type: 'application/javascript' })
          await audioContext.audioWorklet.addModule(URL.createObjectURL(blob))

          sdft = new AudioWorkletNode(audioContext, 'pianolizer-node')
          sdft.port.onmessage = event => {
            // TODO: use SharedArrayBuffer for syncing levels
            levels = event.data
            window.requestAnimationFrame(draw)
          }

          audioSource = audioContext.createMediaElementSource(audioElement)
          audioSource.connect(sdft)
        }

        audioSource.connect(audioContext.destination)
        sdft.parameters.get('smooth').value = parseFloat(document.getElementById('smoothing').value)
      }

      async function setupMicrophone () {
        await setupAudio()
        audioSource.disconnect(audioContext.destination)

        if (microphoneSource === undefined) {
          navigator.mediaDevices.getUserMedia(
            { audio: true, video: false }
          ).then(stream => {
            microphoneSource = audioContext.createMediaStreamSource(stream)
            microphoneSource.connect(sdft)
          }).catch(() => window.alert('Microphone access denied'))
        } else {
          microphoneSource.connect(sdft)
        }
      }

      document.getElementById('source').onchange = event => {
        audioElement.pause()

        const selectedValue = event.target.value
        if (selectedValue === '*') {
          // microphone source
          audioElement.style['pointer-events'] = 'none'
          setupMicrophone()
        } else {
          // <audio> element source
          try { microphoneSource.disconnect(sdft) } catch { console.warn('Microphone was not connected') }
          audioElement.style['pointer-events'] = 'auto'
          audioElement.src = `${selectedValue}?_=${Date.now()}` // never cache
        }
      }

      audioElement.onplay = () => {
        setupAudio()
        audioElement.play()
      }

      document.getElementById('rotation').oninput = event => {
        if (palette !== undefined) {
          palette.rotation = event.target.value
        }
      }

      document.getElementById('smoothing').oninput = event => {
        const value = parseFloat(event.target.value)
        document.getElementById('smoothing-value').innerText = value.toFixed(3)
        if (sdft !== undefined) {
          sdft.parameters.get('smooth').value = value
        }
      }
    </script>
  </body>
</html>