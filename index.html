<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <title>ðŸŽ¹</title>
    <script src="js/piano.js"></script>
    <style>
      body {
        background-color: #000;
        color: #fff;
      }
      .piano-key {
        stroke: #444;
        fill: #000;
      }
    </style>
  </head>
  <body>
    <div>
      <label>
        Source:
        <select id="source">
          <option value="*">ðŸŽ™ Microphone</option>
          <option value="audio/mazurka.webm" selected="selected">Chopin Mazurka in F minor, op. 68 no. 4 (by Pianotomy)</option>
          <option value="audio/chromatic.mp3">Chromatic scale on a piano, ascending</option>
          <option value="audio/sin.wav">Sine wave, 440 Hz</option>
          <option value="audio/saw.wav">Sawtooth wave, 440 Hz</option>
          <option value="audio/squ.wav">Square wave, 440 Hz</option>
          <option value="audio/noise.wav">Pink noise</option>
        </select>
      </label>
    </div>
    <div>
      <audio id="input" src="audio/mazurka.webm" controls></audio>
    </div>
    <div style="text-align: center">
      <svg id="keyboard"></svg>
    </div>
    <script>
      const audioElement = document.getElementById('input')

      // eslint-disable-next-line no-undef
      const pianoKeyboard = new PianoKeyboard(document.getElementById('keyboard'))

      let palette
      let audioContext
      let audioSource
      let microphoneSource
      let sdft

      async function setupAudio () {
        if (audioContext === undefined) {
          await fetch('palette.json')
            .then(response => response.json())
            // eslint-disable-next-line no-undef
            .then(data => { palette = new Palette(data) })

          audioContext = new (window.AudioContext || window.webkitAudioContext)()
          await audioContext.audioWorklet.addModule('js/sdft.js')
          sdft = new AudioWorkletNode(audioContext, 'sliding-dft-node')
          sdft.port.onmessage = event => {
            // TODO: use SharedArrayBuffer for syncing levels
            if (event.data.levels !== undefined) {
              const keyColors = palette.getKeyColors(event.data.levels)
              pianoKeyboard.update(keyColors)
            }
          }

          audioSource = audioContext.createMediaElementSource(audioElement)
          audioSource.connect(sdft)
        }

        sdft.connect(audioContext.destination)
      }

      async function setupMicrophone () {
        await setupAudio()
        sdft.disconnect(audioContext.destination)

        if (microphoneSource === undefined) {
          navigator.getUserMedia =
            navigator.getUserMedia ||
            navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia
          navigator.getUserMedia(
            { audio: true, video: false },
            stream => {
              microphoneSource = audioContext.createMediaStreamSource(stream)
              microphoneSource.connect(sdft)
            },
            () => window.alert('Microphone access denied')
          )
        } else {
          microphoneSource.connect(sdft)
        }
      }

      document.getElementById('source').addEventListener('change', event => {
        audioElement.pause()

        const selectedValue = event.target.value
        if (selectedValue === '*') {
          // microphone source
          audioElement.style['pointer-events'] = 'none'
          setupMicrophone()
        } else {
          // <audio> element source
          try { microphoneSource.disconnect(sdft) } catch { console.warn('Microphone was not connected') }
          audioElement.style['pointer-events'] = 'auto'
          audioElement.src = selectedValue
        }
      })

      audioElement.addEventListener('play', () => {
        setupAudio()
        audioElement.play()
      })
    </script>
  </body>
</html>